{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59bacbc5",
   "metadata": {},
   "source": [
    "# DynCoCluster: A Parallel Co-Clustering Framework for Recommender Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accf6eea",
   "metadata": {},
   "source": [
    "This notebook implements the DynCoCluster framework proposed in the SCI research paper. The model leverages parallel co-clustering for efficient recommendation using the Amazon Product Reviews dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef44a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, average_precision_score\n",
    "import time\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c599aaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Amazon Reviews dataset (100k subset)\n",
    "file_path = 'amazon_100k.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4c88a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the dataset\n",
    "df.dropna(subset=['reviewerID', 'asin', 'overall'], inplace=True)\n",
    "df['reviewerID'] = LabelEncoder().fit_transform(df['reviewerID'])\n",
    "df['asin'] = LabelEncoder().fit_transform(df['asin'])\n",
    "df = df[['reviewerID', 'asin', 'overall']]\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31246abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_matrix = df.pivot_table(index='reviewerID', columns='asin', values='overall').fillna(0)\n",
    "user_item_matrix = user_item_matrix.astype(np.float32)\n",
    "user_item_matrix.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09962d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def parallel_co_clustering(matrix, n_user_clusters=10, n_item_clusters=10):\n",
    "    user_clusters = KMeans(n_clusters=n_user_clusters).fit_predict(matrix)\n",
    "    item_clusters = KMeans(n_clusters=n_item_clusters).fit_predict(matrix.T)\n",
    "    clustered_matrix = np.zeros_like(matrix)\n",
    "    for u in range(n_user_clusters):\n",
    "        for i in range(n_item_clusters):\n",
    "            mask_u = user_clusters == u\n",
    "            mask_i = item_clusters == i\n",
    "            cluster_mean = matrix[np.ix_(mask_u, mask_i)].mean()\n",
    "            clustered_matrix[np.ix_(mask_u, mask_i)] = cluster_mean\n",
    "    return clustered_matrix\n",
    "\n",
    "start_time = time.time()\n",
    "clustered_matrix = parallel_co_clustering(user_item_matrix.values)\n",
    "execution_time = time.time() - start_time\n",
    "execution_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca7acf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate ground truth and predicted matrix\n",
    "y_true = user_item_matrix.values.flatten()\n",
    "y_pred = clustered_matrix.flatten()\n",
    "\n",
    "# Compute scores\n",
    "precision = precision_score(y_true > 3, y_pred > 3)\n",
    "recall = recall_score(y_true > 3, y_pred > 3)\n",
    "f1 = f1_score(y_true > 3, y_pred > 3)\n",
    "map_score = average_precision_score(y_true > 3, y_pred)\n",
    "\n",
    "precision, recall, f1, map_score\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
